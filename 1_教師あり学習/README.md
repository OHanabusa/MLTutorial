# 教師あり学習
ここではニューラルネットワークを用いた教師あり学習の理論を紹介する．その後，実際にプログラムを動かし，学習が行われる様子を体験してもらう．

# 教師あり学習の理論
まず，教師あり学習では，入力データとその正解のラベルが
<p align="center">
  <img src="(https://github.com/SolidMechanicsGroup/ML_Tutorial_2024/files/14504751/nn.pdf)" width="75%">
</p>
ニューラルネットワークを用いた教師あり学習における学習の手順は以下の通りである．
1. 順伝播（Forward Propagation）：ニューラルネットワークにおいて情報を入力した際，入力層から出力層へ順方向として出力が計算される．各層の出力は，入力とバイアス・重み行列と呼ばれる変数を行列計算し，活性化関数に入力することで計算される．
2. 誤差の計算：損失関数を用いて，出力と正解の誤差が計算される．また，損失関数は学習モデルの性能を評価するための関数でもある．
3. 逆伝播（Backward Propagation）：出力層から入力層に向かって順伝搬とは逆方向に，各層の誤差が計算される．各層の誤差は，その層の重み行列と活性化関数の勾配に基づいて計算される．さらに，各ノードの誤差は，直前の層に伝播される
4.  勾配の計算：各層での誤差を用いて，各バイアス・重みの勾配が計算される．勾配は，損失関数を各重みで偏微分することで計算される．この際，連鎖則を用いて，誤差がどのように前の層に伝播するか計算される．
5.  バイアス・重みの更新：勾配降下法やその変種を用いて，各バイアス・重みが更新される．

以上の手順を各入力データに対して行うことによって，学習が進み，出力が正解に近づく．

[Cross entropy loss](https://qiita.com/kenta1984/items/59a9ef1788e6934fd962)
